{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/laevad/78uK7ry1QQWiZp9w/blob/master/soilution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FKfn4LN1UnIx"
      },
      "outputs": [],
      "source": [
        "from zipfile import ZipFile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2f-C6qIU4jF"
      },
      "outputs": [],
      "source": [
        "with ZipFile (\"/content/drive/MyDrive/A-CROPPED.zip\",\"r\") as zipObj:\n",
        "  zipObj.extractall(\"/content/drive/MyDrive/out\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uui6c4p_WKyl"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os #for file management"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a0Vd3uMIWLKE"
      },
      "outputs": [],
      "source": [
        "base_dir = '/content/drive/MyDrive/out/A-CROPPED' #setting the base_dir variable to the location of the dataset containing the images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vIJDEGpWQN2",
        "outputId": "7fe24474-9489-47e2-e5ab-a1cb6a70e470"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 18472 images belonging to 4 classes.\n",
            "Found 4618 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "#now we will do some preprocessing, i.e we are preparing the raw data to make it suitable for a building and training models\n",
        "IMAGE_SIZE = 256 #image size that we are going to set the images in the dataset to.\n",
        "BATCH_SIZE = 64 #the number of images we are inputting into the neural network at once.\n",
        "\n",
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator( #preprocessing our image\n",
        "    rescale = 1./255, #firstly, rescaling it to 1/255 which will make the file size smaller, hence reducing the training time\n",
        "    validation_split=0.2 #secondly, normally a dataset has a test set and a training set, \n",
        "    #validation set is normally to test our neural network,which would give us a measure of accuracy on how well the neural network will do on the predictions.\n",
        "    #here we are telling keras to use 20% for validation and 80% training\n",
        ")\n",
        "\n",
        "train_generator = datagen.flow_from_directory( #training generator\n",
        "    base_dir, #the directory having the fruits and vegetable photos\n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE),  #converting images to 256 by 256\n",
        "    batch_size = BATCH_SIZE, #images getting inputed into the neural network through each epoch or each step\n",
        "    subset='training' #the name we will call it\n",
        ")\n",
        "val_generator = datagen.flow_from_directory(  #validation generator\n",
        "    base_dir, \n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    subset='validation'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a95vm8JLWS7s",
        "outputId": "4f8ab955-b116-47a0-af11-97bf15fae3fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'CLAY': 0, 'LOAM': 1, 'SAND': 2, 'SILT': 3}\n"
          ]
        }
      ],
      "source": [
        "#Next we have to create a labels.txt file that will hold all our labels (important for Flutter)\n",
        "print(train_generator.class_indices) #prints every single key and class of that dataset\n",
        "labels = '\\n'.join(sorted(train_generator.class_indices.keys())) #print all these keys as a list of labels into a text file called labels.txt\n",
        "with open('labels.txt', 'w') as f: #writes to the labels.txt file, and if it doesnt exists, it creates one, and if it does exist, it will overrite it. (thats what 'w' is for)\n",
        "    f.write(labels)\n",
        "\n",
        "#preprocessing of raw data is hence complete and now its time to build our neural network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NKzfvfAWVp9",
        "outputId": "3e1ca322-c9fa-4584-9505-0a80a1920ecd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9406464/9406464 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "#building a neural network using transfer learning method where we take a pretrained neural network called MobileNetV2 which is a convolutional neural network architecture that seeks to perform well on mobile devices and can predict up to 80 different classes\n",
        "#we are going to have a base model on top of which we are going to add pre trained neural network to have it predict the classes we want\n",
        "IMG_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, 3) \n",
        "base_model = tf.keras.applications.MobileNetV2( #grabbing pretrained neural network of choice\n",
        "    input_shape=IMG_SHAPE,\n",
        "    include_top=False, #this will freeze all the weights, because we dont have to retrain and change the weights, instead just add on to the MobileNetV2 CNN, so it clasiffies 5 classes instead of 80\n",
        "    weights='imagenet'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "swZ5WSNwWgPM"
      },
      "outputs": [],
      "source": [
        "base_model.trainable=False #this freezes all the neurons for our base model\n",
        "model = tf.keras.Sequential([ #neural networks act in a sequence of layers, so we add layers as we want\n",
        "  base_model,\n",
        "  tf.keras.layers.Conv2D(32,3, activation = 'relu'), #This layer creates a convolution kernel that is convolved with the layer input to produce a tensor of outputs. Bascially, it trying to understand the patterns of the image\n",
        "  tf.keras.layers.Dropout(0.2), #This layer prevents Neural Networks from Overfitting, i.e being too precise to a point where the NN is only able to recognize images that are present in the dataset\n",
        "  tf.keras.layers.GlobalAveragePooling2D(), #This layer calculates the average output of each feature map in the previous layer, thus reducing the data significantly and preparing the model for the final layer\n",
        "  tf.keras.layers.Dense(4, #no.of classes\n",
        "                        activation='softmax')\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTi335_4Wis0"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(), #Adam is a popular optimiser, designed specifically for training deep neural networks\n",
        "    loss='categorical_crossentropy', \n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "86y-7qw6Wkxc",
        "outputId": "92db00ff-eba7-4dc7-876b-308b8916c31f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "289/289 [==============================] - 320s 1s/step - loss: 0.3551 - accuracy: 0.8752 - val_loss: 1.8426 - val_accuracy: 0.5801\n",
            "Epoch 2/10\n",
            "289/289 [==============================] - 288s 996ms/step - loss: 0.1656 - accuracy: 0.9401 - val_loss: 1.6092 - val_accuracy: 0.6184\n",
            "Epoch 3/10\n",
            "289/289 [==============================] - 280s 969ms/step - loss: 0.1314 - accuracy: 0.9521 - val_loss: 2.1096 - val_accuracy: 0.6046\n",
            "Epoch 4/10\n",
            "289/289 [==============================] - 275s 953ms/step - loss: 0.1060 - accuracy: 0.9620 - val_loss: 2.1175 - val_accuracy: 0.6176\n",
            "Epoch 5/10\n",
            "289/289 [==============================] - 277s 958ms/step - loss: 0.1005 - accuracy: 0.9620 - val_loss: 2.1836 - val_accuracy: 0.6358\n",
            "Epoch 6/10\n",
            "289/289 [==============================] - 271s 939ms/step - loss: 0.0817 - accuracy: 0.9698 - val_loss: 3.2789 - val_accuracy: 0.5868\n",
            "Epoch 7/10\n",
            "289/289 [==============================] - 272s 943ms/step - loss: 0.0704 - accuracy: 0.9740 - val_loss: 2.5198 - val_accuracy: 0.6427\n",
            "Epoch 8/10\n",
            "289/289 [==============================] - 266s 922ms/step - loss: 0.0684 - accuracy: 0.9750 - val_loss: 2.8292 - val_accuracy: 0.6345\n",
            "Epoch 9/10\n",
            "289/289 [==============================] - 269s 932ms/step - loss: 0.0532 - accuracy: 0.9803 - val_loss: 2.5410 - val_accuracy: 0.6574\n",
            "Epoch 10/10\n",
            "289/289 [==============================] - 267s 924ms/step - loss: 0.0539 - accuracy: 0.9801 - val_loss: 2.8941 - val_accuracy: 0.6511\n"
          ]
        }
      ],
      "source": [
        "epochs = 10 #higher the epochs, more accurate is the NN, however it could cause Overfitting, if too high\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs = epochs, \n",
        "    validation_data=val_generator\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUsgNTTQWmKt",
        "outputId": "6df1c316-43e1-43c4-a166-a88a2c826125"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenetv2_1.00_224_input with unsupported characters which will be renamed to mobilenetv2_1_00_224_input in the SavedModel.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Function `signature_wrapper` contains input name(s) mobilenetv2_1.00_224_input with unsupported characters which will be renamed to mobilenetv2_1_00_224_input in the SavedModel.\n",
            "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "#now that we have our neural network trained with tensorflow and keras, we can export it \n",
        "saved_model_dir = '' #means current directory\n",
        "tf.saved_model.save(model, saved_model_dir) #saves to the current directory\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir) \n",
        "tflite_model = converter.convert() #converts our model into a .tflite model which flutter uses for ondevice machine learning\n",
        "\n",
        "with open('model.tflite', 'wb') as f: #to write the converted model into a file, written as binary so add 'wb' instead of 'w'\n",
        "  f.write(tflite_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8vwZrNbaXD0V"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "mount_file_id": "1XUy84xnh0buQXCgokp-5fVw-US2D8Iql",
      "authorship_tag": "ABX9TyPh2hD9c8usVhwchhEta+hE",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}